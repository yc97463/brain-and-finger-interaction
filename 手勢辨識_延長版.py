import cv2
import mediapipe as mp
import math
import random
import time
import numpy as np
from PIL import Image, ImageDraw, ImageFont

mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands

# å…¨åŸŸè¨­å®šè®Šæ•¸
MIN_NUMBER = 0  # æ¸¬é©—æ•¸å­—æœ€å°å€¼
MAX_NUMBER = 7  # æ¸¬é©—æ•¸å­—æœ€å¤§å€¼

# å…¨åŸŸå­—é«”å¿«å–
_font_cache = {}

# ä¸­æ–‡å­—é«”é¡¯ç¤ºå‡½æ•¸
def put_chinese_text(img, text, position, font_size=30, color=(255, 255, 255), font_path=None):
    """
    åœ¨OpenCVåœ–åƒä¸Šé¡¯ç¤ºä¸­æ–‡æ–‡å­—
    """
    global _font_cache
    
    # å°‡OpenCVåœ–åƒè½‰æ›ç‚ºPILåœ–åƒ
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # å‰µå»ºå­—é«”å¿«å–éµ
    cache_key = f"{font_path or 'default'}_{font_size}"
    
    # æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦å·²æœ‰å­—é«”
    if cache_key in _font_cache:
        font = _font_cache[cache_key]
    else:
        # å˜—è©¦è¼‰å…¥ä¸­æ–‡å­—é«”
        font = None
        try:
            if font_path:
                font = ImageFont.truetype(font_path, font_size)
            else:
                # å˜—è©¦ç³»çµ±é è¨­ä¸­æ–‡å­—é«”
                font_paths = [
                    # macOS ç³»çµ±å­—é«”
                    # "/System/Library/Fonts/STHeiti Medium.ttc",
                    # "/System/Library/Fonts/STHeiti Light.ttc",
                    "/Users/yc97463/Library/Fonts/jf-jinxuan-3.1-bold.otf",
                    "/Users/yc97463/Library/Fonts/jf-jinxuan-3.1-medium.otf",
                    "/System/Library/Fonts/Helvetica.ttc",
                    # Windows ç³»çµ±å­—é«”
                    "C:/Windows/Fonts/msyh.ttc",
                    "C:/Windows/Fonts/simhei.ttf",
                    # Linux ç³»çµ±å­—é«”
                    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
                    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"
                ]
                
                for path in font_paths:
                    try:
                        font = ImageFont.truetype(path, font_size)
                        break
                    except:
                        continue
                        
                # å¦‚æœæ‰€æœ‰å­—é«”éƒ½è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨é è¨­å­—é«”
                if font is None:
                    font = ImageFont.load_default()
                    
        except Exception as e:
            print(f"å­—é«”è¼‰å…¥éŒ¯èª¤: {e}")
            font = ImageFont.load_default()
        
        # å°‡å­—é«”å­˜å…¥å¿«å–
        _font_cache[cache_key] = font
    
    # ç¹ªè£½æ–‡å­—
    draw.text(position, text, font=font, fill=color)
    
    # è½‰æ›å›OpenCVæ ¼å¼
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    return img_cv

# åŸæœ‰çš„è§’åº¦è¨ˆç®—å‡½æ•¸
def vector_2d_angle(v1, v2):
    v1_x = v1[0]
    v1_y = v1[1]
    v2_x = v2[0]
    v2_y = v2[1]
    try:
        angle_ = math.degrees(math.acos((v1_x*v2_x+v1_y*v2_y)/(((v1_x**2+v1_y**2)**0.5)*((v2_x**2+v2_y**2)**0.5))))
    except:
        angle_ = 180
    return angle_

# åŸæœ‰çš„æ‰‹æŒ‡è§’åº¦è¨ˆç®—å‡½æ•¸
def hand_angle(hand_):
    angle_list = []
    # thumb å¤§æ‹‡æŒ‡è§’åº¦
    angle_ = vector_2d_angle(
        ((int(hand_[0][0])- int(hand_[2][0])),(int(hand_[0][1])-int(hand_[2][1]))),
        ((int(hand_[3][0])- int(hand_[4][0])),(int(hand_[3][1])- int(hand_[4][1])))
        )
    angle_list.append(angle_)
    # index é£ŸæŒ‡è§’åº¦
    angle_ = vector_2d_angle(
        ((int(hand_[0][0])-int(hand_[6][0])),(int(hand_[0][1])- int(hand_[6][1]))),
        ((int(hand_[7][0])- int(hand_[8][0])),(int(hand_[7][1])- int(hand_[8][1])))
        )
    angle_list.append(angle_)
    # middle ä¸­æŒ‡è§’åº¦
    angle_ = vector_2d_angle(
        ((int(hand_[0][0])- int(hand_[10][0])),(int(hand_[0][1])- int(hand_[10][1]))),
        ((int(hand_[11][0])- int(hand_[12][0])),(int(hand_[11][1])- int(hand_[12][1])))
        )
    angle_list.append(angle_)
    # ring ç„¡åæŒ‡è§’åº¦
    angle_ = vector_2d_angle(
        ((int(hand_[0][0])- int(hand_[14][0])),(int(hand_[0][1])- int(hand_[14][1]))),
        ((int(hand_[15][0])- int(hand_[16][0])),(int(hand_[15][1])- int(hand_[16][1])))
        )
    angle_list.append(angle_)
    # pink å°æ‹‡æŒ‡è§’åº¦
    angle_ = vector_2d_angle(
        ((int(hand_[0][0])- int(hand_[18][0])),(int(hand_[0][1])- int(hand_[18][1]))),
        ((int(hand_[19][0])- int(hand_[20][0])),(int(hand_[19][1])- int(hand_[20][1])))
        )
    angle_list.append(angle_)
    return angle_list

# åŸæœ‰çš„æ‰‹å‹¢åˆ¤æ–·å‡½æ•¸ï¼Œä½†åªä¿ç•™æ•¸å­—åˆ¤æ–·
def hand_pos(finger_angle):
    f1 = finger_angle[0]   # å¤§æ‹‡æŒ‡è§’åº¦
    f2 = finger_angle[1]   # é£ŸæŒ‡è§’åº¦
    f3 = finger_angle[2]   # ä¸­æŒ‡è§’åº¦
    f4 = finger_angle[3]   # ç„¡åæŒ‡è§’åº¦
    f5 = finger_angle[4]   # å°æ‹‡æŒ‡è§’åº¦

    # åªåˆ¤æ–·æ•¸å­—æ‰‹å‹¢
    if f1>=50 and f2>=50 and f3>=50 and f4>=50 and f5>=50:
        return '0'
    elif f1>=50 and f2<50 and f3>=50 and f4>=50 and f5>=50:
        return '1'
    elif f1>=50 and f2<50 and f3<50 and f4>=50 and f5>=50:
        return '2'
    elif f1>=50 and f2<50 and f3<50 and f4<50 and f5>50:
        return '3'
    elif f1>=50 and f2<50 and f3<50 and f4<50 and f5<50:
        return '4'
    elif f1<50 and f2<50 and f3<50 and f4<50 and f5<50:
        return '5'
    elif f1<50 and f2>=50 and f3>=50 and f4>=50 and f5<50:
        return '6'
    elif f1<50 and f2<50 and f3>=50 and f4>=50 and f5>=50:
        return '7'
    elif f1<50 and f2<50 and f3<50 and f4>=50 and f5>=50:
        return '8'
    elif f1<50 and f2<50 and f3<50 and f4<50 and f5>=50:
        return '9'
    else:
        return ''

def main():
    # é¦–å…ˆå˜—è©¦åˆ—å‡ºå¯ç”¨çš„æ”å½±æ©Ÿ
    print("ğŸ” æ­£åœ¨æª¢æ¸¬å¯ç”¨çš„æ”å½±æ©Ÿ...")
    
    # å˜—è©¦ä¸åŒçš„æ”å½±æ©Ÿç´¢å¼•
    camera_indices = [0, 1, 2, -1]  # -1 é€šå¸¸ä»£è¡¨é è¨­æ”å½±æ©Ÿ
    cap = None
    working_index = None
    
    for index in camera_indices:
        print(f"å˜—è©¦æ”å½±æ©Ÿç´¢å¼• {index}...")
        test_cap = cv2.VideoCapture(index)
        
        # åœ¨ macOS ä¸Šï¼Œæœ‰æ™‚éœ€è¦è¨­å®šå¾Œç«¯
        if test_cap.isOpened():
            # å˜—è©¦è®€å–ä¸€å¹€ä¾†ç¢ºèªæ”å½±æ©ŸçœŸçš„å¯ç”¨
            ret, frame = test_cap.read()
            if ret and frame is not None:
                print(f"âœ… æ”å½±æ©Ÿç´¢å¼• {index} å¯ç”¨")
                cap = test_cap
                working_index = index
                break
            else:
                print(f"âŒ æ”å½±æ©Ÿç´¢å¼• {index} ç„¡æ³•è®€å–ç•«é¢")
                test_cap.release()
        else:
            print(f"âŒ æ”å½±æ©Ÿç´¢å¼• {index} ç„¡æ³•é–‹å•Ÿ")
            test_cap.release()
    
    # å¦‚æœæ‰€æœ‰ç´¢å¼•éƒ½å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨ä¸åŒçš„å¾Œç«¯
    if cap is None:
        print("ğŸ”„ å˜—è©¦ä½¿ç”¨ä¸åŒçš„æ”å½±æ©Ÿå¾Œç«¯...")
        backends = [cv2.CAP_AVFOUNDATION, cv2.CAP_V4L2, cv2.CAP_DSHOW]
        backend_names = ["AVFoundation (macOS)", "V4L2 (Linux)", "DirectShow (Windows)"]
        
        for i, backend in enumerate(backends):
            try:
                print(f"å˜—è©¦ {backend_names[i]} å¾Œç«¯...")
                test_cap = cv2.VideoCapture(0, backend)
                if test_cap.isOpened():
                    ret, frame = test_cap.read()
                    if ret and frame is not None:
                        print(f"âœ… {backend_names[i]} å¾Œç«¯å¯ç”¨")
                        cap = test_cap
                        working_index = 0
                        break
                    else:
                        test_cap.release()
                else:
                    test_cap.release()
            except Exception as e:
                print(f"âŒ {backend_names[i]} å¾Œç«¯å¤±æ•—: {e}")
    
    # æª¢æŸ¥æ”å½±æ©Ÿæ˜¯å¦æˆåŠŸé–‹å•Ÿ
    if cap is None or not cap.isOpened():
        print("âŒ ç„¡æ³•é–‹å•Ÿä»»ä½•æ”å½±æ©Ÿï¼Œè«‹æª¢æŸ¥ï¼š")
        print("1. æ”å½±æ©Ÿæ˜¯å¦è¢«å…¶ä»–ç¨‹å¼ä½¿ç”¨ï¼ˆå¦‚ Zoomã€Teamsã€FaceTime ç­‰ï¼‰")
        print("2. æ”å½±æ©Ÿæ¬Šé™æ˜¯å¦å·²é–‹å•Ÿ")
        print("   - macOS: ç³»çµ±åå¥½è¨­å®š > å®‰å…¨æ€§èˆ‡éš±ç§ > éš±ç§æ¬Š > æ”å½±æ©Ÿ")
        print("   - Windows: è¨­å®š > éš±ç§æ¬Š > æ”å½±æ©Ÿ")
        print("3. æ”å½±æ©Ÿæ˜¯å¦æ­£å¸¸é€£æ¥")
        print("4. å˜—è©¦é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼")
        if cap:
            cap.release()
        return
    
    print(f"âœ… æˆåŠŸé–‹å•Ÿæ”å½±æ©Ÿ (ç´¢å¼•: {working_index})")
    
    # è¨­å®šæ”å½±æ©Ÿåƒæ•¸
    print("âš™ï¸ è¨­å®šæ”å½±æ©Ÿåƒæ•¸...")
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    # é©—è­‰è¨­å®šæ˜¯å¦æˆåŠŸ
    actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    actual_fps = cap.get(cv2.CAP_PROP_FPS)
    print(f"ğŸ“¹ æ”å½±æ©Ÿè¨­å®š: {int(actual_width)}x{int(actual_height)} @ {actual_fps:.1f}fps")
    
    fontFace = cv2.FONT_HERSHEY_SIMPLEX
    lineType = cv2.LINE_AA

    # Game variables
    correct_count = 0
    target_number = None
    show_gift = False
    answer_confirmed = False
    answer_display_time = 0
    wrong_answer_confirmed = False  # New: track if wrong answer was confirmed
    stable_frames = 0  # New: count how many frames the same number appears
    last_detected_number = None  # New: keep track of the last detected number
    REQUIRED_STABLE_FRAMES = 45  # å»¶é•·è‡³45å¹€ (ç´„1.5ç§’) è®“å­©ç«¥æœ‰æ›´å¤šæ™‚é–“ç©©å®šæ‰‹å‹¢
    
    # å»¶é•·æ™‚é–“è¨­å®šï¼Œé©åˆç™¼å±•å»¶é²çš„å­©ç«¥
    PREPARATION_DELAY = 10  # å»¶é•·è‡³10ç§’è®“å­©ç«¥æœ‰å……è¶³æ™‚é–“æº–å‚™
    RESULT_DISPLAY_DELAY = 8  # å»¶é•·è‡³8ç§’è®“å­©ç«¥æœ‰è¶³å¤ æ™‚é–“ç†è§£çµæœ
    
    # New: Game state variables
    game_state = "WAITING"  # States: WAITING, RECOGNIZING, SHOWING_RESULT
    state_start_time = time.time()
    countdown_value = PREPARATION_DELAY

    print("ğŸ¤– åˆå§‹åŒ– MediaPipe...")
    try:
        with mp_hands.Hands(
            model_complexity=0,
            min_detection_confidence=0.4,  # é™ä½æª¢æ¸¬é–€æª»ï¼Œè®“æ‰‹å‹¢æ›´å®¹æ˜“è¢«è¾¨è­˜
            min_tracking_confidence=0.4) as hands:  # é™ä½è¿½è¹¤é–€æª»ï¼Œæé«˜ç©©å®šæ€§

            print("ğŸ® éŠæˆ²é–‹å§‹ï¼æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'r' é‡æ–°é–‹å§‹")
            w, h = 640, 480

            while True:
                ret, img = cap.read()
                if not ret:
                    print("âŒ ç„¡æ³•è®€å–æ”å½±æ©Ÿç•«é¢")
                    break
                
                img = cv2.resize(img, (w,h))
                img = cv2.flip(img, 1)
                
                if target_number is None:
                    target_number = random.randint(MIN_NUMBER, MAX_NUMBER)
                    game_state = "WAITING"
                    state_start_time = time.time()
                    countdown_value = PREPARATION_DELAY
                
                # Process the current game state
                current_time = time.time()
                elapsed_time = current_time - state_start_time
                
                # State: WAITING (preparation phase)
                if game_state == "WAITING":
                    # Update countdown timer
                    countdown_value = max(0, PREPARATION_DELAY - int(elapsed_time))
                    
                    # Display target number and countdown with larger, more visible text
                    img = put_chinese_text(img, f"æº–å‚™å¥½äº†å—ï¼Ÿè«‹æ¯”å‡ºé€™å€‹æ•¸å­—ï¼š", (30, 30), 25, (255, 255, 255))
                    cv2.putText(img, f"{target_number}", (w//2-40, h//2), 
                                fontFace, 6, (0, 255, 0), 8, lineType)  # æ›´å¤§æ›´ç²—çš„æ•¸å­—
                    img = put_chinese_text(img, f"å€’æ•¸è¨ˆæ™‚: {countdown_value} ç§’", (30, 400), 35, (0, 165, 255))
                    img = put_chinese_text(img, f"é€£çºŒç­”å°: {correct_count}/3", (30, 450), 30, (255, 255, 255))
                    
                    # Move to recognition state after delay
                    if elapsed_time >= PREPARATION_DELAY:
                        game_state = "RECOGNIZING"
                        state_start_time = current_time
                        stable_frames = 0
                        last_detected_number = None
                
                # State: RECOGNIZING
                elif game_state == "RECOGNIZING":
                    # Display target number with encouraging message
                    img = put_chinese_text(img, f"è«‹æ¯”å‡ºæ•¸å­—:", (30, 55), 35, (255, 255, 255))
                    cv2.putText(img, f"{target_number}", (100, 120),
                                fontFace, 4, (0, 255, 0), 6, lineType)  # æ›´å¤§çš„ç›®æ¨™æ•¸å­—
                    img = put_chinese_text(img, f"é€£çºŒç­”å°: {correct_count}/3", (30, 450), 30, (255, 255, 255))
                    
                    # é¡¯ç¤ºç©©å®šåº¦é€²åº¦æ¢ï¼Œè®“å­©ç«¥çŸ¥é“éœ€è¦ä¿æŒæ‰‹å‹¢
                    progress = min(stable_frames / REQUIRED_STABLE_FRAMES, 1.0)
                    bar_width = 200
                    bar_height = 20
                    bar_x = w - bar_width - 30
                    bar_y = 100
                    
                    # ç¹ªè£½é€²åº¦æ¢èƒŒæ™¯
                    cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (100, 100, 100), -1)
                    # ç¹ªè£½é€²åº¦æ¢å‰æ™¯
                    cv2.rectangle(img, (bar_x, bar_y), (bar_x + int(bar_width * progress), bar_y + bar_height), (0, 255, 0), -1)
                    img = put_chinese_text(img, "ä¿æŒæ‰‹å‹¢", (bar_x, bar_y - 30), 20, (255, 255, 255))
                    
                    # Hand gesture recognition
                    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    results = hands.process(img2)
                    
                    if results.multi_hand_landmarks:
                        hand_numbers = []
                        
                        for hand_landmarks in results.multi_hand_landmarks:
                            mp_drawing.draw_landmarks(
                                img,
                                hand_landmarks,
                                mp_hands.HAND_CONNECTIONS,
                                mp_drawing_styles.get_default_hand_landmarks_style(),
                                mp_drawing_styles.get_default_hand_connections_style())

                            finger_points = []
                            for i in hand_landmarks.landmark:
                                x = i.x*w
                                y = i.y*h
                                finger_points.append((x,y))
                            
                            if finger_points:
                                finger_angle = hand_angle(finger_points)
                                hand_number = hand_pos(finger_angle)
                                if hand_number:
                                    hand_numbers.append(hand_number)
                        
                        # Process detected hand gestures
                        if hand_numbers:
                            detected_numbers = sorted([int(num) for num in hand_numbers if num.isdigit()])
                            
                            # Show detected numbers with larger font
                            for i, num in enumerate(detected_numbers):
                                img = put_chinese_text(img, f"åµæ¸¬åˆ°: {str(num)}", (30 + i*150, 180), 40, (221, 255, 97))
                            
                            # Get the first detected number (if any)
                            current_number = detected_numbers[0] if detected_numbers else None
                            
                            # Check if the number is stable
                            if current_number == last_detected_number:
                                stable_frames += 1
                            else:
                                stable_frames = 0
                                
                            last_detected_number = current_number
                            
                            # Only confirm answer after stable frames threshold
                            if stable_frames >= REQUIRED_STABLE_FRAMES:
                                game_state = "SHOWING_RESULT"
                                state_start_time = current_time
                                
                                if target_number in detected_numbers:
                                    answer_confirmed = True
                                    wrong_answer_confirmed = False
                                    correct_count += 1
                                    if correct_count >= 3:
                                        show_gift = True
                                else:
                                    answer_confirmed = False
                                    wrong_answer_confirmed = True
                    else:
                        # æ²’æœ‰åµæ¸¬åˆ°æ‰‹å‹¢æ™‚é‡ç½®ç©©å®šå¹€æ•¸
                        stable_frames = 0
                        last_detected_number = None
                        img = put_chinese_text(img, "è«‹å°‡æ‰‹æ”¾åœ¨é¡é ­å‰", (30, 230), 35, (255, 255, 0))
                
                # State: SHOWING_RESULT
                elif game_state == "SHOWING_RESULT":
                    # Display remaining display time
                    remaining_time = max(0, RESULT_DISPLAY_DELAY - int(elapsed_time))
                    img = put_chinese_text(img, f"ä¸‹ä¸€é¡Œå€’æ•¸: {remaining_time} ç§’", (w-250, 30), 30, (255, 255, 255))
                    
                    # Display target number
                    img = put_chinese_text(img, f"ç›®æ¨™æ•¸å­—: {target_number}", (30, 30), 35, (255, 255, 255))
                    img = put_chinese_text(img, f"é€£çºŒç­”å°: {correct_count}/3", (30, 450), 30, (255, 255, 255))
                    
                    # Display 'Wonderful!' for completing 3 in a row
                    if show_gift:
                        img = put_chinese_text(img, "å¤ªæ£’äº†ï¼", (w//2-80, h//2-70), 80, (255, 255, 255))
                        img = put_chinese_text(img, "é€£çºŒç­”å°3é¡Œï¼", (w//2-120, h//2), 45, (255, 255, 255))
                    # Display feedback based on answer
                    elif answer_confirmed:
                        img = put_chinese_text(img, "ç­”å°äº†ï¼", (w//2-80, h//2-30), 80, (0, 255, 0))
                        img = put_chinese_text(img, "åšå¾—å¾ˆå¥½ï¼", (w//2-90, h//2+40), 45, (0, 255, 0))
                    elif wrong_answer_confirmed:
                        img = put_chinese_text(img, "å†è©¦ä¸€æ¬¡ï¼", (w//2-90, h//2-30), 70, (0, 100, 255))
                        img = put_chinese_text(img, "æ²’é—œä¿‚ï¼Œç¹¼çºŒåŠ æ²¹ï¼", (w//2-140, h//2+40), 35, (0, 100, 255))
                    
                    # Move to next number after delay
                    if elapsed_time >= RESULT_DISPLAY_DELAY:
                        if show_gift:
                            correct_count = 0
                            show_gift = False
                        target_number = random.randint(MIN_NUMBER, MAX_NUMBER)
                        game_state = "WAITING"
                        state_start_time = current_time
                        stable_frames = 0
                        last_detected_number = None
                        answer_confirmed = False
                        wrong_answer_confirmed = False

                cv2.imshow('Hand Gesture Game - ç™¼å±•å»¶é²å­©ç«¥ç‰ˆ', img)
                key = cv2.waitKey(5)
                if key == ord('q'):
                    break
                # Reset game if 'r' is pressed
                elif key == ord('r'):
                    correct_count = 0
                    target_number = random.randint(MIN_NUMBER, MAX_NUMBER)
                    show_gift = False
                    answer_confirmed = False
                    wrong_answer_confirmed = False
                    stable_frames = 0
                    last_detected_number = None
                    game_state = "WAITING"
                    state_start_time = time.time()

    except Exception as e:
        print(f"âŒ MediaPipe åˆå§‹åŒ–å¤±æ•—: {e}")
    finally:
        print("ğŸ”„ æ¸…ç†è³‡æº...")
        if cap:
            cap.release()
        cv2.destroyAllWindows()
        print("âœ… ç¨‹å¼çµæŸ")

if __name__ == '__main__':
    main() 